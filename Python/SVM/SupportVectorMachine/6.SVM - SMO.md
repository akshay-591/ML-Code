**Sequential minimal optimization** 

SMO or Sequential minimal optimization is one of the best and fastest algorithm for solving SVM optimization problems till now since 1998. It is invented by John C Platt in 1988. 

Before going into deeper lets first look at some basics and also some previous algorithm which was available for training SVM before SMO. 

In mid-90’s SVM was one of the best ML algorithm to solve problems like hand written digit recognition, face detection but due to slow, difficult training algorithm for solving SVM,  made it limited to only limited researcher and engineers. 

In 1998 John C Platt provided an efficient and easy to implement algorithm named as Sequential Minimal Optimization before this two algorithm was in work one was invented by Vladimir Vapnik named as “Chunking algorithm” and second was invented by Osuna in 1997 kind of improved version of Chunking algorithm. 

Let’s talk about them in details 

As we know our Objective Function which we want to minimize is  

(→) = ∑ ∑ (→ ,→ )** 

- ∑                   ( )![](6.SVM%20-%20SMO.001.png)
- =

\=

`  `,     ≤ ≤ **,**  

∑ =** 

\=

Above problem (1) is QP problem which we need to solve. In order to make the above function positive definite the kernel function K must obey the mercer’s condition. 

The KKT condition are necessary and Sufficient condition for an optimal point of a positive definite QP problem. The KKT condition for QP problem (1) is simple, 

- ⟺ ≥ **,** 

< < ⟺ =                                    **(2)** 

- ⟺ ≤** 

Where  is the predicted output by SVM for *ith* training example. **Chunking algorithm**  

The QP problem above (1) involves a matrix that has number of element equal to square of the number of training example. Now the chunking algorithm uses the fact that the value of quadratic form is still the same if we remove the examples which are related to Zero Lagrange multipliers. Therefore, the large QP problem can be broken down into a series of smaller QP problem, whose aim is to find the all non-zero Lagrange multipliers which resemble to those example which are known as support vectors and rest Lagrange multiplies are removed. At every step chunking solves a problem that consists of following problems. 

- every non – zero Lagrange multipliers from last step and the M worst example that violates the KKT conditions (2). If there are fewer than *M* examples that violate the KKT conditions at a step, all of the violating examples are added in.*  
- Each QP sub-problem is initialized with the results of the previous sub-problem. At the last step, the entire set of non-zero Lagrange multipliers has been identified, hence the last step solves the large QP problem. 

Chunking seriously reduces the size of the matrix from the number of training examples squared to approximately the number of non-zero Lagrange multipliers squared.  

![](6.SVM%20-%20SMO.002.png)

**Figure 1.** Three alternative methods for training SVMs: Chunking, Osuna’s algorithm, and SMO. For each method, three steps are illustrated. The horizontal thin line at every step represents the training set, while the thick boxes represent the Lagrange multipliers being optimized at that step. For chunking, a fixed number of examples are added every step, while the zero Lagrange multipliers are discarded at every step. Thus, the number of examples trained per step tends to grow. For Osuna’s algorithm, a fixed number of examples are optimized every step: the same number of examples is added to and discarded from the problem at every step. For SMO, only two examples are analytically optimized at every step, so that each step is very fast. 

**Osuna algorithm** 

In 1997, Osuna, proved a theorem which suggests a whole new set of QP algorithms 

for SVMs. The theorem proves that the large QP problem can be broken down into a series of smaller QP sub-problems. As long as at least one example that violates the KKT conditions is added to the examples for the previous sub-problem, each step will reduce the overall objective function and maintain a feasible point that obeys all of the constraints. Therefore, a sequence of QP sub-problems that always add at least one violator will be guaranteed to converge. Notice that the chunking algorithm obeys the conditions of the theorem, and hence will converge. 

Osuna, suggests keeping a constant size matrix for every QP sub-problem, which implies adding and deleting the same number of examples at every step (see figure 1). Using a constant-size matrix will allow the training on arbitrarily sized data sets.  

The algorithm given in Osuna’s paper suggests adding one example and subtracting one example every step. Clearly this would be inefficient, because it would use an entire numerical QP optimization step to cause one training example to obey the KKT conditions. In practice, researchers add and subtract multiple examples according to unpublished heuristics. 

in Above both algorithm as mentioned in John plats paper at that time memory was one of the issue if we have example matrix more than 4000 examples. Even though today memory is not that big of a issue but both algorithm a uses numerical QP solver and Numerical QP is notoriously tricky to get right there are many numerical precision issues that need to be addressed. 

**Sequential minimal optimization** 

Now there is one more algorithm knows as Coordinate ascent algorithm, let’s look at it in brief In coordinate ascent algorithm if have some unconstrained problem and we want minimize it  

min ( …………….. )

So in coordinate ascent what we do is optimize only one parameter at time and keep the rest of the 

parameter constant. 

But we cannot apply this algorithm, on SVM problem let’s see why  

Let's say we have set of  that satisfy the constraints of our SVM objective function (1). Now, suppose we want to hold  ……. fixed and take a coordinate ascent step and optimize the objective function with respect to . Can we make any progress? The answer is no, because the equality constraint in (1) ensures that,     

- − ∑ 

= Or, by multiplying both sides by  we equivalently have, 

- −  ∑ 

\=

`  `is exactly determined by the other  ′ and if we were to hold  ……. fixed then we can't make any change to  without violating the equality constraint in the optimization problem. Thus, if we want to 

update some subject of the  , we must update at least two of them simultaneously in order to keep satisfying the constraints. This motivates the SMO algorithm.  

SMO algorithm can quickly solve the SVM QP problem without any extra matrix storage and without using numerical QP libraries SMO decomposes the overall QP problem into small QP problem using Osuna’s theorem to ensure convergence. 

To  solve  SVM  problem  SMO  optimizes  the  two  multipliers  in  single  step  to  make  sure  that  equality constrained  must  be  obeyed  by  the  multipliers.  Choice  of  Two  multipliers  depends  on  the  heuristics (heuristics means steps for choosing best variable or function which gives us the best optimization) after optimizing these two multipliers SMO updates the SVM to reflect the change. 

The advantage of SMO lies in the fact that solving for two Lagrange multipliers can be done analytically. Thus, numerical QP optimization is avoided entirely. The inner loop of the algorithm can be expressed in a short amount of C code, rather than invoking an entire QP library routine. Even though more optimization sub problems are solved in the course of the algorithm, each sub-problem is so fast that the overall QP problem is solved quickly. 

Now there are Two steps in Solving SMO  

1. Methods for optimizing Lagrange multipliers analytically 
1. Choosing Lagrange multipliers for optimization by heuristics. 

To be considered as optimized the Lagrange multipliers must have to fulfil the both constrained inequality and equality.  

Now let’s say we are optimizing  and  and keeping the rest constant so by using our equality we get, 

+ = − ∑ 

\=

As we know right hand side is constant let’s take it equal ‘k’, 

+ =

` `when  = + =

![](6.SVM%20-%20SMO.003.png)

And when  ≠ − =

![](6.SVM%20-%20SMO.004.png)

By interpretation from the figures we can say that, inequality constrained keeps the multipliers in box that is between 0 and C and equality constrained keep them on diagonal line. So that means single step of SMO should find an optimum of the objective function on diagonal line. 

***Methods for solving two Lagrange multipliers*** 

In order to solve the Lagrange Multipliers first SMO will compute the constrains on these chosen multipliers and then constrains minimum. The line we saw in figure above we can also say the ends of the line as bounds/limit between 0 and C.  

Let’s take the Lower limit of the bound or Lower end of the Line as *L*, Upper limit of the bound or Upper end as *H*.  

So L and H should lie between the 0 and C and to fulfil the constrains Lagrange multiplier should lie between L and H.  

L and H can be calculated as 

When  ≠

- ( , − )  **,**       = ( ,    +  − )            **(3)** 

When  = ,**   

- ( , + − )**,**         = ( ,  + )                       **(4)** 

The second derivative of objective function (11) along the diagonal line can be expressed as  

- (→ , → ) +  (→ , → ) −  (→ , →                       **(5)** )

Under normal circumstances objective function will going to positive definite direction of linear equality constrains and  (eta) will be positive in that case SMO computes the minimum along the direction of the constrains  

- ( − )                                                    **(6)** +

Where    ℎ   = − ,  and   is the SVM prediction on *ith* example, 

Next step will clip the on the diagonal line to full fill the equality constrains  

≥

, =                       < <                       **(7)**

`  `≤

{

Now let s =  **,** value of   will be calculated using   , , 

- + ( −  , )                                         **(8)**

When kernel K does not obey the mercer’s condition  will not going to positive because of the indefinite objective function. In other case a zero   can also occur with correct kernel if more than one example has same input. 

In both those cases  will be calculated by calculating the objective function (11) at each end of the line segment that. 

At  = **,**

- ∑ ∑ (→ ,→ )  − ∑                                 **(9) ![](6.SVM%20-%20SMO.005.png)**

\=

\=

\=

And  =

- ∑ ∑ (→ ,→ )  − ∑                                **(10) ![](6.SVM%20-%20SMO.006.png)**

\=

\=

\=

Now, 

\> +

, = < −                         **(11)**

`      `,                    

{

Here,  is tolerance usually will be equal to − **.** 

**Heuristics for Choosing Lagrange multipliers for optimization** 

As long as SMO always optimizes and alters two Lagrange multipliers at every step and at least one of the Lagrange multipliers violated the KKT conditions before the step, then each step will decrease the objective function according to Osuna’s theorem. Convergence is thus guaranteed. In order to speed convergence, SMO uses heuristics to choose which two Lagrange multipliers to jointly optimize. 

**Heuristics for first choice:** 

- Loop over the entire dataset and determine which example violates the KKT condition. 
- If an example Violates the KKT condition within some tolerance say, 10−3 then that example is eligible for optimization. 
- After iteration over entire dataset loop over the examples whose related Lagrange multiplier is are neither 0 and nor c. Again these example checked against the KKT condition within some tolerance and example violates The KKT condition (12) eligible for optimization. 
- Loop continues over non bound example until every example obeys KKT condition. 
- After looping over non bound example outer loop iterates over entire dataset again. 
- The outer loop keeps alternating between single passes over entire training set and non-bound example until the entire training set obeys the KKT condition then algorithm terminates. 

The first choice heuristic concentrates the CPU time on the examples that are most likely to violate the KKT conditions the non-bound subset. As the SMO algorithm progresses, examples that are at the bounds are likely to stay at the bounds, while examples that are not at the bounds will move as other examples are optimized.  The  SMO  algorithm  will  then  iterate  over  the  non-bound  subset  until  that  subset  is  self- consistent, then SMO will scan the entire data set to search for any bound examples that have become KKT violated due to optimizing the non-bound subset. 

Notice that the KKT conditions are checked to be within some tolerance    of fulfilment. Typically, is set to be 10-3. Because Recognition systems typically do not need to have the KKT conditions fulfilled to high accuracy. it is acceptable for examples on the positive margin to have outputs between 0.999 and 1.001. The SMO algorithm (and other SVM algorithms) will not converge as quickly if it is required to produce very high accuracy output. 

**Heuristics for second choice:** 

Once a first Lagrange multiplier is chosen, SMO chooses the second Lagrange multiplier to maximize the size of the step taken during joint optimization.  

Now, evaluating the kernel function *K* is time consuming, so SMO approximates the step size by the absolute value of the numerator in equation (6) (| − |) SMO keeps a cached error value ***E*** for every non-bound example in the training set and then chooses an error to approximately maximize the step size.  

- If *E*2 is positive, SMO chooses an example with minimum error in cache ***E***.  
- If *E*2 is negative, SMO chooses an example with maximum error in cache ***E***. 

Under  unusual  circumstances,  SMO  cannot  make  positive  progress  using  the  second  choice  heuristic described above.  

For example, positive progress cannot be made if the first and second training examples share identical input vectors *x,* which causes the objective function to become semi-definite. In this case, SMO uses a different method of second choice heuristics until it finds a pair of Lagrange multipliers that can be make positive progress. 

Positive progress can be determined by making a non-zero step size upon joint optimization of the two Lagrange multipliers. The different methods for choosing second Lagrange multipliers are: 

- If the above heuristic does not make positive progress, then SMO starts iterating through the non-bound examples, searching for a second example that can make positive progress.  
- If none of the non-bound examples, make positive progress, then SMO starts iterating through the entire training set until an example is found that makes positive progress.  
- Both the iteration through the non-bound examples and the iteration through the entire training set are started at random locations, in order not to bias SMO towards the examples at the beginning of the training set.  
- In extremely degenerate circumstances, none of the examples will make an adequate second example. When this happens, the first example is skipped and SMO continues with another chosen first example. 

**Computing The Threshold** 

Threshold ‘b’ needs to computed after each step so that KKT condition are full filled by both optimized example. Now there are two formulas which computes the threshold. 

So when only   is not at the bounds that means  < < **,** 

- + ( → → , → , →**                 **(12)** 
- ). ( , ) + ( − ). ( ) +

When only   , is not at the bounds that means  < , <** 

→ → , → →**                  **(13)** 

- + ( − ). ( , ) + ( − ). ( , ) +

When both multipliers are not at the bounds in that case  ,** are going to be equal.  

When both Lagrange multipliers are not at the bound and if L is not equal to H then values between 

`  `are consistent with KKT condition. SMO will choose the threshold to be halfway in between  **.** 

**Pseudo code** 

**X – input matrix** 

**Y – output matrix** 

**Errors – Error cache matrix** 

**K – is vectorised kernel matrix of input matrix X** 

**alphas – is the matrix containing Lagrange multipliers on size of  Y Method no. 3** 

int takeStep (int i1, int i2)  { 

- if (i1==i2)  return 0  // because both example have to be different 
- alpha2 = alphas [ i2 ]       // store old alpha at ‘i2’  
- alpha1= alphas[i1]        // store old alpha at ‘i1’ 
- store y[i], y[j] in y1, y2  
- s = y1\*y2 
- store Errors [ i ], Errors [ j ] in E1 , E2 
- compute L and H equations (3) and (4) 
- if (L == H) return 0 
- calculate eta using equation (5) 
- if (eta > 0)  

{ 

Calculate **a2**     via equation (6) 

if (a2 < L) a2 = L 

`   `else if (a2 > H) a2 = H 

} 

- else 

{ 

L\_obj = objective function via equation (11) at alphas[ i2 ]= L H\_obj = objective function via equation (11) at alphas[ i2 ]= H if (Lobj < Hobj-tol) 

a2 = L 

else if (Lobj > Hobj+tol) 

a2 = H 

else 

a2 = alph2 } 

- if (|a2-alph2| < tol\*(a2+alph2+tol)) return 0 
- a1 = alph1+s\*(alph2-a2) 
- Update threshold using equations (12) and (13) to reflect change in Lagrange multipliers 
- Update error cache using new Lagrange multipliers via equation  To refreshing Errors cache, 

Replace the matrix element to 0 whose lagrange multipler has been optimized. 

And calculate the Errors cache at rest of the indexes using this formula, 

Errors[non\_opt] = Eold [non\_opt] + y1\*(a1 – alpha1) \* K[i1, non\_opt] 

+ y2\*(a2 – alpha1) \* K[i2, non\_opt] + bold - bnew

Here , 

Eold – old Error cache matrix 

non\_opt – non optimize index of alpha matrix. 

- alphas[i1] = a1   Store a1 in the alpha array 
- alphas[i2] = a2   // Store a2 in the alpha array 
- return 1          // end method    

**method no. 2**  

int examineExample(int i2) { 

- y2 = Y[i2] 
- alpha2 = alphas [ i2 ]       // store old alpha at ‘i2’  
- E2 = Errors[i2]  
- r2 = E2\*y2 
- if ((r2 < -tol && alpha2 < C) || (r2 > tol && alpha2 > 0)) 

`    `{ 

`      `if (number of non-zero & non-C alpha > 1) 

`      `{ 

`        `i1 = result of second choice heuristic  

`        `if takeStep(i1,i2) 

`        `return 1 

`            `} 

`   `loop over all non-zero and non-C alpha, starting at a randopoint      { 

`       `i1 = identity of current alpha 

`       `if takeStep(i1,i2) 

`       `return 1 

`      `} 

`   `loop over examples, starting at a random point       { 

`        `i1 = loop variable 

`        `if (takeStep(i1,i2) 

`        `return 1 

`       `} 

`   `} 

`      `return 0       // end method    

} 

**Method no. 1** 

Void main (X, Y, C, tol): 

- b=0; 
- initialize alphas matrix of size equal to number of example and all element to 0. 
- calculate initial Errors on every example ,  −
- numChanged = 0; 
- examineAll = 1; 
- while (numChanged > 0 | examineAll == 1) 

{ 

`  `numChanged = 0; 

`  `if (examineAll == 1) 

`  `{ 

`    `loop I over all training examples 

`    `numChanged += examineExample(I) 

`  `} 

`  `else 

`  `{ 

`     `loop I over examples where alpha is not 0 & not C      numChanged += examineExample(I) 

`  `} 

} 

- if (examineAll == 1)  examineAll = 0 
- else if (numChanged == 0) examineAll = 1 

`   `} // end method 
